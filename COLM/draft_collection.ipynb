{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1b9dbc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install openreview-py and ensure urllib3 stays compatible\n",
        "!pip install openreview-py \"urllib3<2.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0240ab5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import openreview\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "def get_full_conversation(client, venue_id, submission_invitation):\n",
        "    \"\"\"Generic collector: reviews + all discussion responses for a venue.\"\"\"\n",
        "    print(f\"1. Getting submission list ({submission_invitation})...\")\n",
        "    submissions = client.get_all_notes(invitation=submission_invitation)\n",
        "    print(f\"2. Found {len(submissions)} submissions.\")\n",
        "\n",
        "    all_reviews_data = []\n",
        "\n",
        "    for note in tqdm.tqdm(submissions):\n",
        "        paper_id = note.id\n",
        "        paper_title = note.content.get('title', {}).get('value')\n",
        "        paper_number = note.number\n",
        "\n",
        "        # 1. 获取该论文论坛下的所有笔记（包含 Review, Rebuttal, Metareview 等）\n",
        "        forum_notes = client.get_all_notes(forum=paper_id)\n",
        "\n",
        "        # 2. 构建“父子关系图” (Adjacency List)\n",
        "        reply_map = defaultdict(list)\n",
        "        reviews = []\n",
        "        decision_note = None\n",
        "\n",
        "        for n in forum_notes:\n",
        "            if n.replyto:\n",
        "                reply_map[n.replyto].append(n)\n",
        "\n",
        "            if n.invitations and any('Decision' in inv for inv in n.invitations):\n",
        "                decision_note = n\n",
        "\n",
        "            # Official_Review (ICLR) or Review (some venues e.g. COLM)\n",
        "            if n.invitations and (\n",
        "                any('Official_Review' in inv for inv in n.invitations)\n",
        "                or any(inv.endswith('/Review') or inv.endswith('/Official_Review') for inv in (n.invitations or []))\n",
        "            ):\n",
        "                reviews.append(n)\n",
        "\n",
        "        # 获取 Decision 结果\n",
        "        decision_value = \"None\"\n",
        "        if decision_note:\n",
        "            decision_value = decision_note.content.get('decision', {}).get('value', 'None')\n",
        "\n",
        "        # 3. 处理每一篇 Review，抓取其下的完整对话树\n",
        "        for review in reviews:\n",
        "            review_id = review.id\n",
        "            review_content = review.content\n",
        "\n",
        "            # --- 核心逻辑：获取该 Review 下的所有子孙对话 ---\n",
        "            discussion_nodes = get_all_descendants(review_id, reply_map)\n",
        "\n",
        "            # 按时间排序 (tmdate) 保证对话顺序\n",
        "            discussion_nodes.sort(key=lambda x: x.tmdate)\n",
        "\n",
        "            # 格式化对话文本\n",
        "            transcript_lines = []\n",
        "            if discussion_nodes:\n",
        "                for node in discussion_nodes:\n",
        "                    # 1. 识别说话人 (Speaker)\n",
        "                    speaker = \"Unknown\"\n",
        "                    sigs = node.signatures\n",
        "                    if any('Authors' in s for s in sigs):\n",
        "                        speaker = \"Authors\"\n",
        "                    elif any('Reviewer' in s for s in sigs):\n",
        "                        # 尝试提取 Reviewer 编号，如 .../Reviewer_2 -> Reviewer 2\n",
        "                        speaker = sigs[0].split('/')[-1]\n",
        "                    elif any('Area_Chair' in s for s in sigs):\n",
        "                        speaker = \"Area Chair\"\n",
        "\n",
        "                    # 2. 提取内容\n",
        "                    text = node.content.get('comment', {}).get('value', '')\n",
        "                    if not text:\n",
        "                        # 有些早期回复内容可能在 review 字段里，做个兼容\n",
        "                        text = node.content.get('review', {}).get('value', '')\n",
        "\n",
        "                    # 3. 拼接\n",
        "                    transcript_lines.append(f\"[{speaker}]: {text}\")\n",
        "\n",
        "                discussion_transcript = \"\\n\\n\".join(transcript_lines)\n",
        "            else:\n",
        "                discussion_transcript = \"None\"\n",
        "\n",
        "            all_reviews_data.append({\n",
        "                'paper_number': paper_number,\n",
        "                'paper_title': paper_title,\n",
        "                'decision': decision_value,\n",
        "                'review_id': review_id,\n",
        "                'rating': review_content.get('rating', {}).get('value'),\n",
        "                'confidence': review_content.get('confidence', {}).get('value'),\n",
        "                'review_text': review_content.get('review', {}).get('value'),\n",
        "                'discussion_transcript': discussion_transcript  # <--- 新名字，包含完整多轮对话\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(all_reviews_data)\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_iclr_2024_full_conversation():\n",
        "    client = openreview.api.OpenReviewClient(baseurl=\"https://api2.openreview.net\")\n",
        "    venue_id = \"ICLR.cc/2024/Conference\"\n",
        "    return get_full_conversation(client, venue_id, f\"{venue_id}/-/Submission\")\n",
        "\n",
        "\n",
        "def get_colm_2024_full_conversation():\n",
        "    client = openreview.api.OpenReviewClient(baseurl=\"https://api2.openreview.net\")\n",
        "    venue_id = \"colmweb.org/COLM/2024/Conference\"\n",
        "    return get_full_conversation(client, venue_id, f\"{venue_id}/-/Submission\")\n",
        "\n",
        "\n",
        "# --- 辅助函数：递归查找所有子孙节点 ---\n",
        "def get_all_descendants(root_id, reply_map):\n",
        "    \"\"\"\n",
        "    输入 root_id (Review ID) 和 reply_map (父子关系表)\n",
        "    输出该节点下所有的子孙笔记列表 (不包含 root 本身)\n",
        "    \"\"\"\n",
        "    descendants = []\n",
        "    # 找到直接回复 root 的节点\n",
        "    children = reply_map.get(root_id, [])\n",
        "\n",
        "    for child in children:\n",
        "        descendants.append(child)\n",
        "        # 递归：把 child 的子孙也加进来\n",
        "        descendants.extend(get_all_descendants(child.id, reply_map))\n",
        "\n",
        "    return descendants\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from pathlib import Path\n",
        "    out_dir = Path(\"COLM/2024\")\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    out_path = out_dir / \"colm2024_full_transcript.csv\"\n",
        "\n",
        "    df = get_colm_2024_full_conversation()\n",
        "\n",
        "    print(\"\\n---------------- RESULTS ----------------\")\n",
        "    if not df.empty:\n",
        "        print(f\"Collected {len(df)} reviews with full conversation threads.\")\n",
        "        mask = df[\"discussion_transcript\"].str.contains(\"Reviewer\", na=False)\n",
        "        if mask.any():\n",
        "            print(\"\\n--- Sample Conversation ---\")\n",
        "            print(df.loc[mask, \"discussion_transcript\"].iloc[0][:500] + \"...\\n\")\n",
        "        df.to_csv(out_path, index=False)\n",
        "        print(f\"Saved to {out_path}\")\n",
        "    else:\n",
        "        print(\"No data found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83457109",
      "metadata": {},
      "source": [
        "## Run COLM 2024 collection\n",
        "\n",
        "Run the cell below to fetch review opinions and all responses for COLM 2024 and save to `COLM/2024/colm2024_full_transcript.csv`. Ensure your working directory is the repo root (DatasetsPaper)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7508ac3f",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'get_colm_2024_full_conversation' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m OUTPUT_DIR\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m out_path \u001b[38;5;241m=\u001b[39m OUTPUT_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolm2024_full_transcript.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m df_colm \u001b[38;5;241m=\u001b[39m \u001b[43mget_colm_2024_full_conversation\u001b[49m()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---------------- COLM 2024 RESULTS ----------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df_colm\u001b[38;5;241m.\u001b[39mempty:\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_colm_2024_full_conversation' is not defined"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "OUTPUT_DIR = Path(\"COLM/2024\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "out_path = OUTPUT_DIR / \"colm2024_full_transcript.csv\"\n",
        "\n",
        "df_colm = get_colm_2024_full_conversation()\n",
        "\n",
        "print(\"\\n---------------- COLM 2024 RESULTS ----------------\")\n",
        "if not df_colm.empty:\n",
        "    print(f\"Collected {len(df_colm)} reviews with full conversation threads.\")\n",
        "    mask = df_colm[\"discussion_transcript\"].str.contains(\"Reviewer\", na=False)\n",
        "    if mask.any():\n",
        "        print(\"\\n--- Sample conversation ---\")\n",
        "        print(df_colm.loc[mask, \"discussion_transcript\"].iloc[0][:500] + \"...\\n\")\n",
        "    df_colm.to_csv(out_path, index=False)\n",
        "    print(f\"Saved to {out_path}\")\n",
        "else:\n",
        "    print(\"No data found.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
